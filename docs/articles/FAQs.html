<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="emmeans">
<title>FAQs for emmeans • emmeans</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="FAQs for emmeans">
<meta property="og:description" content="emmeans">
<meta property="og:image" content="https://rvlenth.github.io/emmeans/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light" data-bs-theme="light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">emmeans</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.10.2</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/AQuickStart.html">Quick start guide for **emmeans**</a>
    <a class="dropdown-item" href="../articles/basics.html">Basics of estimated marginal means</a>
    <a class="dropdown-item" href="../articles/comparisons.html">Comparisons and contrasts in emmeans</a>
    <a class="dropdown-item" href="../articles/confidence-intervals.html">Confidence intervals and tests in emmeans</a>
    <a class="dropdown-item" href="../articles/FAQs.html">FAQs for emmeans</a>
    <a class="dropdown-item" href="../articles/interactions.html">Interaction analysis in emmeans</a>
    <a class="dropdown-item" href="../articles/messy-data.html">Working with messy data</a>
    <a class="dropdown-item" href="../articles/models.html">Models supported by emmeans</a>
    <a class="dropdown-item" href="../articles/predictions.html">Prediction in **emmeans**</a>
    <a class="dropdown-item" href="../articles/re-engineering-clds.html">Re-engineering CLDs</a>
    <a class="dropdown-item" href="../articles/sophisticated.html">Sophisticated models in emmeans</a>
    <a class="dropdown-item" href="../articles/transformations.html">Transformations and link functions in emmeans</a>
    <a class="dropdown-item" href="../articles/utilities.html">Utilities and options for emmeans</a>
    <a class="dropdown-item" href="../articles/vignette-topics.html">Index of vignette topics</a>
    <a class="dropdown-item" href="../articles/xplanations.html">Explanations supplement</a>
    <a class="dropdown-item" href="../articles/xtending.html">For developers: Extending **emmeans**</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rvlenth/emmeans/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>FAQs for emmeans</h1>
                        <h4 data-toc-skip class="author">emmeans
package, Version 1.10.2</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rvlenth/emmeans/blob/HEAD/vignettes/FAQs.Rmd" class="external-link"><code>vignettes/FAQs.Rmd</code></a></small>
      <div class="d-none name"><code>FAQs.Rmd</code></div>
    </div>

    
    
<!-- @index Vignettes!FAQS; Frequently asked questions -->
<p>This vignette contains answers to questions received from users or
posted on discussion boards like <a href="https://stats.stackexchange.com" class="external-link">Cross Validated</a> and <a href="https://stackoverflow.com/" class="external-link">Stack Overflow</a></p>
<div class="section level2">
<h2 id="contents">Contents<a class="anchor" aria-label="anchor" href="#contents"></a>
</h2>
<ol style="list-style-type: decimal">
<li><a href="#what">What are EMMs/lsmeans?</a></li>
<li><a href="#fastest">What is the fastest way to obtain EMMs and
pairwise comparisons?</a></li>
<li><a href="#nopairs">I wanted comparisons, but all I get is
(nothing)</a></li>
<li><a href="#qdrg">The model I fitted is not supported by
<strong>emmeans</strong></a></li>
<li><a href="#interactions">I have three (or two or four) factors that
interact</a></li>
<li><a href="#trends">I have covariate(s) that interact(s) with
factor(s)</a></li>
<li><a href="#polys">I have covariate(s) and am fitting a polynomial
model</a></li>
<li><a href="#CIerror">Some “significant” comparisons have overlapping
confidence intervals</a></li>
<li><a href="#notfactor">All my pairwise comparisons have the same
<em>P</em> value</a></li>
<li><a href="#numeric">emmeans() doesn’t work as expected</a></li>
<li><a href="#NAs">All or some of the results are NA</a></li>
<li><a href="#model">If I analyze subsets of the data separately, I get
different results</a></li>
<li><a href="#transformations">My lsmeans/EMMs are way off from what I
expected</a></li>
<li><a href="#asymp">Why do I get <code>Inf</code> for the degrees of
freedom?</a></li>
<li><a href="#additive">I get exactly the same comparisons for each “by”
group</a></li>
<li><a href="#anova">My ANOVA <em>F</em> is significant, but no pairwise
comparisons are</a></li>
<li><a href="#ratios">I wanted differences, but instead I got ratios (or
odds ratios)</a></li>
<li><a href="#notukey">I asked for a Tukey adjustments, but that’s not
what I got</a></li>
<li><a href="#noadjust"><code>emmeans()</code> completely ignores my
P-value adjustments</a></li>
<li><a href="#nowelch"><code>emmeans()</code> gives me pooled <em>t</em>
tests, but I expected Welch’s <em>t</em></a></li>
</ol>
<p><a href="vignette-topics.html">Index of all vignette topics</a></p>
</div>
<div class="section level2">
<h2 id="what">What are EMMs/lsmeans?<a class="anchor" aria-label="anchor" href="#what"></a>
</h2>
<!-- @index EMMs!What are they?; Least-squares means -->
<p>Estimated marginal means (EMMs), a.k.a. least-squares means, are
predictions on a reference grid of predictor settings, or marginal
averages thereof. See details in <a href="basics.html">the “basics”
vignette</a>.</p>
</div>
<div class="section level2">
<h2 id="fastest">What is the fastest way to obtain EMMs and pairwise
comparisons?<a class="anchor" aria-label="anchor" href="#fastest"></a>
</h2>
<!-- @index Model!Importance of; `emmeans()`!Fastest way to get wrong answers -->
<p>There are two answers to this (i.e., be careful what you wish
for):</p>
<ol style="list-style-type: decimal">
<li>Don’t think; just fit the first model that comes to mind and run
<code>emmeans(model, pairwise ~ treatment)</code>. This is the fastest
way; however, the results have a good chance of being invalid.</li>
<li>
<em>Do</em> think: Make sure you fit a model that really explains
the responses. Do diagnostic residual plots, include appropriate
interactions, account for heteroscadesticity if necessary, etc. This is
the fastest way to obtain <em>appropriate</em> estimates and
comparisons.</li>
</ol>
<p>The point here is that <code><a href="../reference/emmeans.html">emmeans()</a></code> summarizes the
<em>model</em>, not the data directly. If you use a bad model, you will
get bad results. And if you use a good model, you will get appropriate
results. It’s up to you: it’s your research—is it important?</p>
<p><a href="#contents">Back to Contents</a></p>
</div>
<div class="section level2">
<h2 id="nopairs">I wanted comparisons, but all I get is (nothing)<a class="anchor" aria-label="anchor" href="#nopairs"></a>
</h2>
<!-- @index Comparisons result in `(nothing)`; `(nothing)` in output@nothing -->
<p>This happens when you have only one estimate; and you can’t compare
it with itself! This is turn can happen when you have a situation like
this: you have fitted</p>
<pre><code><span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">RT</span> <span class="op">~</span> <span class="va">treat</span>, data <span class="op">=</span> <span class="va">mydata</span><span class="op">)</span></span></code></pre>
<p>and <code>treat</code> is coded in your dataset with numbers 1, 2, 3,
… . Since <code>treat</code> is a numeric predictor,
<code><a href="../reference/emmeans.html">emmeans()</a></code> just reduces it to a single number, its mean,
rather than separate values for each treatment. Also, please note that
this is almost certainly NOT the model you want, because it forces an
assumption that the treatment effects all fall on a straight line. You
should fit a model like</p>
<pre><code><span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">RT</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">treat</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">mydata</span><span class="op">)</span></span></code></pre>
<p>then you will have much better luck with comparisons.</p>
</div>
<div class="section level2">
<h2 id="qdrg">The model I fitted is not supported by <strong>emmeans</strong><a class="anchor" aria-label="anchor" href="#qdrg"></a>
</h2>
<!-- @index Models!Unsupported; `qdrg()` -->
<p>You may still be able to get results using <code><a href="../reference/qdrg.html">qdrg()</a></code> (quick
and dirty reference grid). See <code><a href="../reference/qdrg.html">?qdrg</a></code> for details and
examples.</p>
</div>
<div class="section level2">
<h2 id="interactions">I have three (or two or four) factors that interact<a class="anchor" aria-label="anchor" href="#interactions"></a>
</h2>
<!-- @index Multi-factor studies; Simple comparisons -->
<p>Perhaps your question has to do with interacting factors, and you
want to do some kind of <em>post hoc</em> analysis comparing levels of
one (or more) of the factors on the response. Some specific versions of
this question…</p>
<ul>
<li>Perhaps you tried to do a simple comparison for one treatment and
got a warning message you don’t understand</li>
<li>You do pairwise comparisons of factor combinations and it’s just too
much – want just some of them</li>
<li>How do I even approach this?</li>
</ul>
<p>My first answer is: plots almost always help. If you have factors A,
B, and C, try something like <code>emmip(model, A ~ B | C)</code>, which
creates an interaction-style plot of the predictions against B, for each
A, with separate panels for each C. This will help visualize what
effects stand out in a practical way. This can guide you in what
post-hoc tests would make sense. See the <a href="interactions.html">“interactions” vignette</a> for more discussion
and examples.</p>
<p><a href="#contents">Back to Contents</a></p>
</div>
<div class="section level2">
<h2 id="trends">I have covariate(s) that interact(s) with factor(s)<a class="anchor" aria-label="anchor" href="#trends"></a>
</h2>
<!-- @index Covariates!Interacting with factors -->
<p>This is a situation where it may well be appropriate to compare the
slopes of trend lines, rather than the EMMs. See the
<code>help("emtrends"()</code>“)` and the discussion of this topic in <a href="interactions.html#covariates">the “interactions” vignette</a></p>
</div>
<div class="section level2">
<h2 id="polys">I have covariate(s) and am fitting a polynomial model<a class="anchor" aria-label="anchor" href="#polys"></a>
</h2>
<p>You need to be careful to define the reference grid consistently. For
example, if you use covariates <code>x</code> and <code>xsq</code>
(equal to <code>x^2</code>) to fit a quadratic curve, the default
reference grid uses the mean of each covariate – and
<code>mean(xsq)</code> is usually not the same as
<code>mean(x)^2</code>. So you need to use <code>at</code> to ensure
that the covariates are set consistently with respect to the model. See
<a href="basics.html#depcovs">this subsection of the “basics”
vignette</a> for an example.</p>
</div>
<div class="section level2">
<h2 id="CIerror">Some “significant” comparisons have overlapping confidence
intervals<a class="anchor" aria-label="anchor" href="#CIerror"></a>
</h2>
<!-- @index Confidence intervals!Overlapping; Comparisons!with overlapping CIs@over -->
<p>That can happen because <em>it is just plain wrong to use
[non-]overlapping CIs for individual means to do comparisons</em>. Look
at the printed results from something like
<code>emmeans(mymodel, pairwise ~ treatment)</code>. In particular, note
that the <code>SE</code> values are <em>not</em> the same*, and may even
have different degrees of freedom. Means are one thing statistically,
and differences of means are quite another thing. Don’t ever mix them
up, and don’t ever use a CI display for comparing means.</p>
<p>I’ll add that making hard-line decisions about “significant” and
“non-significant” is in itself a poor practice. See <a href="basics.html#pvalues">the discussion in the “basics”
vignette</a></p>
</div>
<div class="section level2">
<h2 id="notfactor">All my pairwise comparisons have the same <em>P</em> value<a class="anchor" aria-label="anchor" href="#notfactor"></a>
</h2>
<p>This will happen if you fitted a model where the treatments you want
to compare were put in as a numeric predictor; for example
<code>dose</code>, with values of 1, 2, and 3. If <code>dose</code> is
modeled as numeric, you will be fitting a linear trend in those dose
values, rather than a model that allows those doses to differ in
arbitrary ways. Go back and fit a different model using
<code>factor(dose)</code> instead; it will make all the difference. This
is closely related to the next topic.</p>
</div>
<div class="section level2">
<h2 id="numeric">emmeans() doesn’t work as expected<a class="anchor" aria-label="anchor" href="#numeric"></a>
</h2>
<!-- @index Covariates!`emmeans()` doesn't work; Covariates!`cov.keep`; Covariates!`cov.reduce`;  -->
<p>Equivalently, users ask how to get <em>post hoc</em> comparisons when
we have covariates rather than factors. Yes, it does work, but you have
to tell it the appropriate reference grid.</p>
<p>But before saying more, I have a question for you: <em>Are you sure
your model is meaningful?</em></p>
<ul>
<li>If your question concerns <em>only</em> two-level predictors such as
<code>sex</code> (coded 1 for female, 2 for male), no problem. The model
will produce the same predictions as you’d get if you’d used these as
factors.</li>
<li>If <em>any</em> of the predictors has 3 or more levels, you may have
fitted a nonsense model, in which case you need to fit a different model
that does make sense before doing any kind of <em>post hoc</em>
analysis. For instance, the model contains a covariate
<code>brand</code> (coded 1 for Acme, 2 for Ajax, and 3 for Al’s), this
model is implying that the difference between Acme and Ajax is exactly
equal to the difference between Ajax and Al’s, owing to the fact that a
linear trend in <code>brand</code> has been fitted. If you had instead
coded 1 for Ajax, 2 for Al’s, and 3 for Acme, the model would produce
different fitted values. Ask yourself if it makes sense to have
<code>brand = 2.319</code>. If not, you need to fit another model using
<code>factor(brand)</code> in place of <code>brand</code>.</li>
</ul>
<p>Assuming that the appropriateness of the model is settled, the
current version of <strong>emmeans</strong> automatically casts
two-value covariates as factors, but not covariates having higher
numbers of unique values. Suppose your model has a covariate
<code>dose</code> which was experimentally varied over four levels, but
can sensibly be interpreted as a numerical predictor. If you want to
include the separate values of <code>dose</code> rather than the mean
<code>dose</code>, you can do that using something like
<code>emmeans(model, "dose", at = list(dose = 1:4))</code>, or
<code>emmeans(model, "dose", cov.keep = "dose")</code>, or
<code>emmeans(model, "dose", cov.keep = "4")</code>. There are small
differences between these. The last one regards any covariate having 4
or fewer unique values as a factor.</p>
<p>See “altering the reference grid” in the <a href="basics.html#altering">“basics” vignette</a> for more
discussion.</p>
<p><a href="#contents">Back to Contents</a></p>
</div>
<div class="section level2">
<h2 id="NAs">All or some of the results are NA<a class="anchor" aria-label="anchor" href="#NAs"></a>
</h2>
<!-- @index `NA`s in the output; `NonEst` values; Estimability issues -->
<p>The <strong>emmeans</strong> package uses tools in the
<strong>estimability</strong> package to determine whether its results
are uniquely estimable. For example, in a two-way model with
interactions included, if there are no observations in a particular cell
(factor combination), then we cannot estimate the mean of that cell.</p>
<p>When <em>some</em> of the EMMs are estimable and others are not, that
is information about missing information in the data. If it’s possible
to remove some terms from the model (particularly interactions), that
may make more things estimable if you re-fit with those terms excluded;
but don’t delete terms that are really needed for the model to fit
well.</p>
<p>When <em>all</em> of the estimates are non-estimable, it could be
symptomatic of something else. Some possibilities include:</p>
<ul>
<li>An overly ambitious model; for example, in a Latin square design,
interaction effects are confounded with main effects; so if any
interactions are included in the model, you will render main effects
inestimable.</li>
<li>Possibly you have a nested structure that needs to be included in
the model or specified via the <code>nesting</code> argument. Perhaps
the levels that B can have depend on which level of A is in force. Then
B is nested in A and the model should specify <code>A + A:B</code>, with
no main effect for <code>B</code>.</li>
<li>Modeling factors as numeric predictors (see also the <a href="#numeric">related section on covariates</a>). To illustrate,
suppose you have data on particular state legislatures, and the model
includes the predictors <code>state_name</code> as well as
<code>dem_gov</code> which is coded 1 if the governor is a Democrat and
0 otherwise. If the model was fitted with <code>state_name</code> as a
factor or character variable, but <code>dem_gov</code> as a numeric
predictor, then, chances are, <code><a href="../reference/emmeans.html">emmeans()</a></code> will return
non-estimable results. If instead, you use <code>factor(dem_gov)</code>
in the model, then the fact that <code>state_name</code> is nested in
<code>dem_gov</code> will be detected, causing EMMs to be computed
separately for each party’s states, thus making things estimable.</li>
<li>Some other things may in fact be estimable. For illustration, it’s
easy to construct an example where all the EMMs are non-estimable, but
pairwise comparisons are estimable:</li>
</ul>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span><span class="va">pigs</span>, x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">10</span>, <span class="fl">9</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">pg.lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">conc</span><span class="op">)</span> <span class="op">~</span> <span class="va">x</span> <span class="op">+</span> <span class="va">source</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">percent</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">pg</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">pg.lm</span>, <span class="va">consec</span> <span class="op">~</span> <span class="va">percent</span><span class="op">)</span></span></code></pre></div>
<pre class="ro"><code><span><span class="co">## $emmeans</span></span>
<span><span class="co">##  percent emmean SE df asymp.LCL asymp.UCL</span></span>
<span><span class="co">##        9 nonEst NA NA        NA        NA</span></span>
<span><span class="co">##       12 nonEst NA NA        NA        NA</span></span>
<span><span class="co">##       15 nonEst NA NA        NA        NA</span></span>
<span><span class="co">##       18 nonEst NA NA        NA        NA</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Results are averaged over the levels of: source </span></span>
<span><span class="co">## Results are given on the log (not the response) scale. </span></span>
<span><span class="co">## Confidence level used: 0.95 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $contrasts</span></span>
<span><span class="co">##  contrast              estimate     SE df t.ratio p.value</span></span>
<span><span class="co">##  percent12 - percent9    0.1796 0.0561 23   3.202  0.0114</span></span>
<span><span class="co">##  percent15 - percent12   0.0378 0.0582 23   0.650  0.8613</span></span>
<span><span class="co">##  percent18 - percent15   0.0825 0.0691 23   1.194  0.5201</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Results are averaged over the levels of: source </span></span>
<span><span class="co">## Results are given on the log (not the response) scale. </span></span>
<span><span class="co">## P value adjustment: mvt method for 3 tests</span></span></code></pre>
<p>The <a href="messy-data.html">“messy-data” vignette</a> has more
examples and discussion.</p>
<p><a href="#contents">Back to Contents</a></p>
</div>
<div class="section level2">
<h2 id="model">If I analyze subsets of the data separately, I get different
results<a class="anchor" aria-label="anchor" href="#model"></a>
</h2>
<!-- @index Analysis of subsets of data; Subsets of data -->
<p>Estimated marginal means summarize the <em>model</em> that you fitted
to the data – not the data themselves. Many of the most common models
rely on several simplifying assumptions – that certain effects are
linear, that the error variance is constant, etc. – and those
assumptions are passed forward into the <code><a href="../reference/emmeans.html">emmeans()</a></code> results.
Doing separate analyses on subsets usually comprises departing from that
overall model, so of course the results are different.</p>
</div>
<div class="section level2">
<h2 id="transformations">My lsmeans/EMMs are way off from what I expected<a class="anchor" aria-label="anchor" href="#transformations"></a>
</h2>
<!-- @index `emmeans()`!Surprising results from; Poisson regression!Surprising results
     Logistic regression!Surprising results -->
<p>First step: Carefully read the annotations below the output. Do they
say something like “results are on the log scale, not the response
scale”? If so, that explains it. A Poisson or logistic model involves a
link function, and by default, <code><a href="../reference/emmeans.html">emmeans()</a></code> produces its
results on that same scale. You can add <code>type = "response"</code>
to the <code><a href="../reference/emmeans.html">emmeans()</a></code> call and it will put the results of the
scale you expect. But that is not always the best approach. The <a href="transformations.html">“transformations” vignette</a> has examples
and discussion.</p>
</div>
<div class="section level2">
<h2 id="asymp">Why do I get <code>Inf</code> for the degrees of freedom?<a class="anchor" aria-label="anchor" href="#asymp"></a>
</h2>
<!-- @index Infinite degrees of freedom; Degrees of freedom!Infinite 
     *z* tests!vs. *t* tests; *t* tests vs. *z* tests -->
<p>This is simply the way that <strong>emmeans</strong> labels
asymptotic results (that is, estimates that are tested against the
standard normal distribution – <em>z</em> tests – rather than the
<em>t</em> distribution). Note that obtaining quantiles or probabilities
from the <em>t</em> distribution with infinite degrees of freedom is the
same as obtaining the corresponding values from the standard normal. For
example:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html" class="external-link">qt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">.9</span>, <span class="fl">.95</span>, <span class="fl">.975</span><span class="op">)</span>, df <span class="op">=</span> <span class="cn">Inf</span><span class="op">)</span></span></code></pre></div>
<pre class="ro"><code><span><span class="co">## [1] 1.281552 1.644854 1.959964</span></span></code></pre>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">qnorm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">.9</span>, <span class="fl">.95</span>, <span class="fl">.975</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre class="ro"><code><span><span class="co">## [1] 1.281552 1.644854 1.959964</span></span></code></pre>
<p>so when you see infinite d.f., that just means its a <em>z</em> test
or a <em>z</em> confidence interval.</p>
<p><a href="#contents">Back to Contents</a></p>
</div>
<div class="section level2">
<h2 id="additive">I get exactly the same comparisons for each “by” group<a class="anchor" aria-label="anchor" href="#additive"></a>
</h2>
<!-- @index `by` groups!Identical comparisons -->
<p>As mentioned elsewhere, EMMs summarize a <em>model</em>, not the
data. If your model does not include any interactions between the
<code>by</code> variables and the factors for which you want EMMs, then
by definition, the effects for the latter will be exactly the same
regardless of the <code>by</code> variable settings. So of course the
comparisons will all be the same. If you think they should be different,
then you are saying that your model should include interactions between
the factors of interest and the <code>by</code> factors.</p>
</div>
<div class="section level2">
<h2 id="anova">My ANOVA <em>F</em> is significant, but no pairwise comparisons
are<a class="anchor" aria-label="anchor" href="#anova"></a>
</h2>
<!-- @index *F* test!vs. pairwise comparisons@pairwz
        Analysis of variance!versus *post hoc* comparisons@post -->
<p>First of all, you should not be making binary decisions of
“significant” or “nonsignificant.” This is a simplistic view of
<em>P</em> values that assigns an unmerited magical quality to the value
0.05. It is suggested that you just report the <em>P</em> values
actually obtained, and let your readers decide how significant your
findings are in the context of the scientific findings.</p>
<p>But to answer the question: This is a common misunderstanding of
ANOVA. If <em>F</em> has a particular <em>P</em> value, this implies
only that <em>some contrast</em> among the means (or effects) has the
same <em>P</em> value, after applying the Scheffe adjustment. That
contrast may be very much unlike a pairwise comparison, especially when
there are several means being compared. Having an <em>F</em> statistic
with a <em>P</em> value of, say, 0.06, does <em>not</em> imply that any
pairwise comparison will have a <em>P</em> value of 0.06 or smaller.
Again referring to the paragraph above, just report the <em>P</em> value
for each pairwise comparison, and don’t try to relate them to the
<em>F</em> statistic.</p>
<p>Another consideration is that by default, <em>P</em> values for
pairwise comparisons are adjusted using the Tukey method, and the
adjusted <em>P</em> values can be quite a bit larger than the unadjusted
ones. (But I definitely do <em>not</em> advocate using no adjustment to
“repair” this problem.)</p>
</div>
<div class="section level2">
<h2 id="ratios">I wanted differences, but instead I got ratios (or odds ratios)<a class="anchor" aria-label="anchor" href="#ratios"></a>
</h2>
<!-- @index Comparisons!Obtaining differences rather than ratios;
            Ratios!but I wanted differences; Odds ratios!but I wanted differences  -->
<p>When a transformation or link involves logs, then, unlike other
transformations, comparisons can be back-transformed into ratios – and
that is the default behavior. If you really want differences and not
ratios, you can re-grid the means first. Re-gridding starts anew with
everything on the response scale, and no memory of the
transformation.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">EMM</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html" class="external-link">pairs</a></span><span class="op">(</span><span class="fu"><a href="../reference/regrid.html">regrid</a></span><span class="op">(</span><span class="va">EMM</span><span class="op">)</span><span class="op">)</span>   <span class="co"># or contrast(regrid(EMM), ...)</span></span></code></pre></div>
<p>PS – A side effect is that this causes the tests to be done using SEs
obtained by the delta method on the re-gridded scale, rather than on the
link scale. Re-gridding can be used with any transformation, not just
logs, and it has the same side effect.</p>
</div>
<div class="section level2">
<h2 id="notukey">I asked for Tukey adjustments, but that’s not what I got<a class="anchor" aria-label="anchor" href="#notukey"></a>
</h2>
<!-- @index Tukey adjustment!Ignored or changed -->
<p>There are two reasons this could happen:</p>
<ol style="list-style-type: decimal">
<li>There is only one comparison in each <code>by</code> group (see next
topic).</li>
<li>A Tukey adjustment is inappropriate. The Tukey adjustment is
appropriate for pairwise comparisons of means. When you have some other
set of contrasts, the Tukey method is deemed unsuitable and the Sidak
method is used instead. A suggestion is to use <code>"mvt"</code>
adjustment (which is exact); we don’t default to this because it can
require a lot of computing time for a large set of contrasts or
comparisons.</li>
</ol>
</div>
<div class="section level2">
<h2 id="noadjust">
<code>emmeans()</code> completely ignores my P-value
adjustments<a class="anchor" aria-label="anchor" href="#noadjust"></a>
</h2>
<!-- @index *P* values!Adjustment is ignored -->
<p>This happens when there are only two means (or only two in each
<code>by</code> group). Thus there is only one comparison. When there is
only one thing to test, there is no multiplicity issue, and hence no
multiplicity adjustment to the <em>P</em> values.</p>
<p>If you wish to apply a <em>P</em>-value adjustment to all tests
across all groups, you need to null-out the <code>by</code> variable and
summarize, as in the following:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">EMM</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">model</span>, <span class="op">~</span> <span class="va">treat</span> <span class="op">|</span> <span class="va">group</span><span class="op">)</span>   <span class="co"># where treat has 2 levels</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html" class="external-link">pairs</a></span><span class="op">(</span><span class="va">EMM</span>, adjust <span class="op">=</span> <span class="st">"sidak"</span><span class="op">)</span>   <span class="co"># adjustment is ignored - only 1 test per group</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html" class="external-link">pairs</a></span><span class="op">(</span><span class="va">EMM</span><span class="op">)</span>, by <span class="op">=</span> <span class="cn">NULL</span>, adjust <span class="op">=</span> <span class="st">"sidak"</span><span class="op">)</span>   <span class="co"># all are in one group now</span></span></code></pre></div>
<p>Note that if you put <code>by = NULL</code> <em>inside</em> the call
to <code><a href="https://rdrr.io/r/graphics/pairs.html" class="external-link">pairs()</a></code>, then this causes all
<code>treat</code>,<code>group</code> combinations to be compared.</p>
<p><a href="#contents">Back to Contents</a></p>
</div>
<div class="section level2">
<h2 id="nowelch">
<code>emmeans()</code> gives me pooled <em>t</em> tests, but I
expected Welch’s <em>t</em><a class="anchor" aria-label="anchor" href="#nowelch"></a>
</h2>
<!-- @index Welch's *t* comparisons; Pooled *t*!Instead of Welch's *t*;
            Model!Importance of getting it right; `emmeans()`!And the underlying model;
            Get the model right first -->
<p>It is important to note that <code><a href="../reference/emmeans.html">emmeans()</a></code> and its relatives
produce results based on the <em>model object</em> that you provide –
not the data. So if your sample SDs are wildly different, a model fitted
using <code><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm()</a></code> or <code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code> is not a good model,
because those R functions use a statistical model that presumes that the
errors have constant variance. That is, the problem isn’t in
<code><a href="../reference/emmeans.html">emmeans()</a></code>, it’s in handing it an inadequate model
object.</p>
<p>Here is a simple illustrative example. Consider a simple one-way
experiment and the following model:</p>
<pre><code><span><span class="va">mod1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov</a></span><span class="op">(</span><span class="va">response</span> <span class="op">~</span> <span class="va">treat</span>, data <span class="op">=</span> <span class="va">mydata</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">mod1</span>, <span class="va">pairwise</span> <span class="op">~</span> <span class="va">treat</span><span class="op">)</span></span></code></pre>
<p>This code will estimate means and comparisons among treatments. All
standard errors, confidence intervals, and <em>t</em> statistics are
based on the pooled residual SD with <em>N - k</em> degrees of freedom
(assuming <em>N</em> observations and <em>k</em> treatments). These
results are useful <em>only</em> if the underlying assumptions of
<code>mod1</code> are correct – including the assumption that the error
SD is the same for all treatments.</p>
<p>Alternatively, you could fit the following model using generalized
least-squares:</p>
<pre><code><span><span class="va">mod2</span> <span class="op">=</span> <span class="fu">nlme</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/gls.html" class="external-link">gls</a></span><span class="op">(</span><span class="va">response</span> <span class="op">~</span> <span class="va">treat</span>, data <span class="op">=</span> <span class="va">mydata</span>,</span>
<span>                 weights <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/varIdent.html" class="external-link">varIdent</a></span><span class="op">(</span>form <span class="op">=</span> <span class="op">~</span><span class="fl">1</span> <span class="op">|</span> <span class="va">treat</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">mod2</span>, <span class="va">pairwise</span> <span class="op">~</span> <span class="va">treat</span><span class="op">)</span></span></code></pre>
<p>This model specifies that the error variance depends on the levels of
<code>treat</code>. This would be a much better model to use when you
have wildly different sample SDs. The results of the
<code><a href="../reference/emmeans.html">emmeans()</a></code> call will reflect this improvement in the
modeling. The standard errors of the EMMs will depend on the individual
sample variances, and the <em>t</em> tests of the comparisons will be in
essence the Welch <em>t</em> statistics with Satterthwaite degrees of
freedom.</p>
<p>To obtain appropriate <em>post hoc</em> estimates, contrasts, and
comparisons, one must first find a model that successfully explains the
peculiarities in the data. This point cannot be emphasized enough. If
you give <code><a href="../reference/emmeans.html">emmeans()</a></code> a good model, you will obtain correct
results; if you give it a bad model, you will obtain incorrect results.
Get the model right <em>first</em>.</p>
<p><a href="#contents">Back to Contents</a></p>
<p><a href="vignette-topics.html">Index of all vignette topics</a></p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Russell V. Lenth.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
